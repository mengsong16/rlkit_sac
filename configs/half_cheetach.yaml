algorithm: "SAC"
version: "normal"
layer_size: 256
replay_buffer_size: 1000000
seed: 1
experiment_prefix: "halfcheetah"
save_every_epochs: 50 

algorithm_kwargs:
  num_epochs: 3000
  num_eval_steps_per_epoch: 5000
  num_trains_per_train_loop: 1000
  num_expl_steps_per_train_loop: 1000
  min_num_steps_before_training: 1000
  max_path_length: 1000
  batch_size: 256
 
trainer_kwargs:
  discount: 0.99
  soft_target_tau: 5.0e-3
  target_update_period: 1
  policy_lr: 3.0e-4
  qf_lr: 3.0e-4
  reward_scale: 1
  use_automatic_entropy_tuning: true